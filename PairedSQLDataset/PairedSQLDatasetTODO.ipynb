{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paired SQL Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook is part of a larger effort to translate artificial languages into each other: \n",
    "https://github.com/fastai/fastai/blob/master/courses/dl2/translate.ipynb\n",
    "http://course.fast.ai/lessons/lesson11.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a dataset, where we build pairs of 2 different SQL dialects with slightly different datamodels. This pair is analogous to what we do in natural language translation with translating e.g. french into english.\n",
    "\n",
    "we use two standard DBs and their SQL dialatecs with a slightly different data model to build pairs of statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Every notebook starts with the following three lines; they ensure that any edits to libraries \n",
    "## you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook.\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "##import numpy as np\n",
    "## import torch\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertChar(mystring, position, chartoinsert ):\n",
    "    longi = len(mystring)\n",
    "    mystring   =  mystring[:position] + chartoinsert + mystring[position:] \n",
    "    return mystring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## O Reilly: Python for Data Analysis, chapter 6.4. Interacting with Databases, p.189\n",
    "\n",
    "drop = \"\"\"DROP TABLE Customer;\"\"\"\n",
    "query = \"\"\"\n",
    " CREATE TABLE IF NOT EXISTS Customer (lastname VARCHAR(40), email VARCHAR(40), networth REAL);\"\"\"\n",
    "con = sqlite3.connect('mydata.sqlite')\n",
    "con.execute(drop)\n",
    "con.execute(query)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite Inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "amountinserts = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"INSERT INTO Customer VALUES ('average1','joe.average1@email.com',10000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet2','piet.yanneke2@email.nl',60000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann3','max.mustermann3@email.de',60000)\",\n",
       " \"INSERT INTO Customer VALUES ('average4','joe.average4@email.com',40000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet5','piet.yanneke5@email.nl',150000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann6','max.mustermann6@email.de',120000)\",\n",
       " \"INSERT INTO Customer VALUES ('average7','joe.average7@email.com',70000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet8','piet.yanneke8@email.nl',240000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann9','max.mustermann9@email.de',180000)\",\n",
       " \"INSERT INTO Customer VALUES ('average10','joe.average10@email.com',100000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet11','piet.yanneke11@email.nl',330000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann12','max.mustermann12@email.de',240000)\",\n",
       " \"INSERT INTO Customer VALUES ('average13','joe.average13@email.com',130000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet14','piet.yanneke14@email.nl',420000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann15','max.mustermann15@email.de',300000)\",\n",
       " \"INSERT INTO Customer VALUES ('average16','joe.average16@email.com',160000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet17','piet.yanneke17@email.nl',510000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann18','max.mustermann18@email.de',360000)\",\n",
       " \"INSERT INTO Customer VALUES ('average19','joe.average19@email.com',190000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet20','piet.yanneke20@email.nl',600000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann21','max.mustermann21@email.de',420000)\",\n",
       " \"INSERT INTO Customer VALUES ('average22','joe.average22@email.com',220000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet23','piet.yanneke23@email.nl',690000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann24','max.mustermann24@email.de',480000)\",\n",
       " \"INSERT INTO Customer VALUES ('average25','joe.average25@email.com',250000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet26','piet.yanneke26@email.nl',780000)\",\n",
       " \"INSERT INTO Customer VALUES ('Mustermann27','max.mustermann27@email.de',540000)\",\n",
       " \"INSERT INTO Customer VALUES ('average28','joe.average28@email.com',280000)\",\n",
       " \"INSERT INTO Customer VALUES ('Piet29','piet.yanneke29@email.nl',870000)\"]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data ={0 : ('Mustermann', 'max.mustermann@email.de', 20000),\n",
    "        1 : ('average', 'joe.average@email.com', 10000),\n",
    "        2 : ('Piet', 'piet.yanneke@email.nl', 30000)\n",
    "        }\n",
    "\n",
    "sqlliteinsertlist =[]\n",
    "i=1\n",
    "while i < amountinserts:\n",
    "    sqlliteinsert = \"INSERT INTO Customer VALUES (\"\n",
    "    sqlliteinsert = sqlliteinsert + \"\\'\" + data[i%len(data)][0] + str(i) + \"\\',\"  + \"\\'\" + insertChar(data[i%len(data)][1], data[i%len(data)][1].find('@'),str(i)) + \"\\',\" + str(i * data[i%len(data)][2]) + \")\" \n",
    "    con.execute(sqlliteinsert)\n",
    "    sqlliteinsertlist.append(sqlliteinsert)\n",
    "    i = i + 1\n",
    "\n",
    "sqlliteinsertlist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average1', 'joe.average1@email.com', 10000.0),\n",
       " ('Piet2', 'piet.yanneke2@email.nl', 60000.0),\n",
       " ('Mustermann3', 'max.mustermann3@email.de', 60000.0),\n",
       " ('average4', 'joe.average4@email.com', 40000.0),\n",
       " ('Piet5', 'piet.yanneke5@email.nl', 150000.0),\n",
       " ('Mustermann6', 'max.mustermann6@email.de', 120000.0),\n",
       " ('average7', 'joe.average7@email.com', 70000.0),\n",
       " ('Piet8', 'piet.yanneke8@email.nl', 240000.0),\n",
       " ('Mustermann9', 'max.mustermann9@email.de', 180000.0),\n",
       " ('average10', 'joe.average10@email.com', 100000.0),\n",
       " ('Piet11', 'piet.yanneke11@email.nl', 330000.0),\n",
       " ('Mustermann12', 'max.mustermann12@email.de', 240000.0),\n",
       " ('average13', 'joe.average13@email.com', 130000.0),\n",
       " ('Piet14', 'piet.yanneke14@email.nl', 420000.0),\n",
       " ('Mustermann15', 'max.mustermann15@email.de', 300000.0),\n",
       " ('average16', 'joe.average16@email.com', 160000.0),\n",
       " ('Piet17', 'piet.yanneke17@email.nl', 510000.0),\n",
       " ('Mustermann18', 'max.mustermann18@email.de', 360000.0),\n",
       " ('average19', 'joe.average19@email.com', 190000.0),\n",
       " ('Piet20', 'piet.yanneke20@email.nl', 600000.0),\n",
       " ('Mustermann21', 'max.mustermann21@email.de', 420000.0),\n",
       " ('average22', 'joe.average22@email.com', 220000.0),\n",
       " ('Piet23', 'piet.yanneke23@email.nl', 690000.0),\n",
       " ('Mustermann24', 'max.mustermann24@email.de', 480000.0),\n",
       " ('average25', 'joe.average25@email.com', 250000.0),\n",
       " ('Piet26', 'piet.yanneke26@email.nl', 780000.0),\n",
       " ('Mustermann27', 'max.mustermann27@email.de', 540000.0),\n",
       " ('average28', 'joe.average28@email.com', 280000.0),\n",
       " ('Piet29', 'piet.yanneke29@email.nl', 870000.0)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute('select lastname, email, networth from Customer')\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('lastname', None, None, None, None, None, None),\n",
       " ('email', None, None, None, None, None, None),\n",
       " ('networth', None, None, None, None, None, None))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastname</th>\n",
       "      <th>email</th>\n",
       "      <th>networth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>average1</td>\n",
       "      <td>joe.average1@email.com</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Piet2</td>\n",
       "      <td>piet.yanneke2@email.nl</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mustermann3</td>\n",
       "      <td>max.mustermann3@email.de</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average4</td>\n",
       "      <td>joe.average4@email.com</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Piet5</td>\n",
       "      <td>piet.yanneke5@email.nl</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mustermann6</td>\n",
       "      <td>max.mustermann6@email.de</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>average7</td>\n",
       "      <td>joe.average7@email.com</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Piet8</td>\n",
       "      <td>piet.yanneke8@email.nl</td>\n",
       "      <td>240000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mustermann9</td>\n",
       "      <td>max.mustermann9@email.de</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>average10</td>\n",
       "      <td>joe.average10@email.com</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Piet11</td>\n",
       "      <td>piet.yanneke11@email.nl</td>\n",
       "      <td>330000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mustermann12</td>\n",
       "      <td>max.mustermann12@email.de</td>\n",
       "      <td>240000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>average13</td>\n",
       "      <td>joe.average13@email.com</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Piet14</td>\n",
       "      <td>piet.yanneke14@email.nl</td>\n",
       "      <td>420000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mustermann15</td>\n",
       "      <td>max.mustermann15@email.de</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>average16</td>\n",
       "      <td>joe.average16@email.com</td>\n",
       "      <td>160000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Piet17</td>\n",
       "      <td>piet.yanneke17@email.nl</td>\n",
       "      <td>510000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mustermann18</td>\n",
       "      <td>max.mustermann18@email.de</td>\n",
       "      <td>360000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>average19</td>\n",
       "      <td>joe.average19@email.com</td>\n",
       "      <td>190000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Piet20</td>\n",
       "      <td>piet.yanneke20@email.nl</td>\n",
       "      <td>600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mustermann21</td>\n",
       "      <td>max.mustermann21@email.de</td>\n",
       "      <td>420000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>average22</td>\n",
       "      <td>joe.average22@email.com</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Piet23</td>\n",
       "      <td>piet.yanneke23@email.nl</td>\n",
       "      <td>690000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mustermann24</td>\n",
       "      <td>max.mustermann24@email.de</td>\n",
       "      <td>480000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>average25</td>\n",
       "      <td>joe.average25@email.com</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Piet26</td>\n",
       "      <td>piet.yanneke26@email.nl</td>\n",
       "      <td>780000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mustermann27</td>\n",
       "      <td>max.mustermann27@email.de</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>average28</td>\n",
       "      <td>joe.average28@email.com</td>\n",
       "      <td>280000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Piet29</td>\n",
       "      <td>piet.yanneke29@email.nl</td>\n",
       "      <td>870000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lastname                      email  networth\n",
       "0       average1     joe.average1@email.com   10000.0\n",
       "1          Piet2     piet.yanneke2@email.nl   60000.0\n",
       "2    Mustermann3   max.mustermann3@email.de   60000.0\n",
       "3       average4     joe.average4@email.com   40000.0\n",
       "4          Piet5     piet.yanneke5@email.nl  150000.0\n",
       "5    Mustermann6   max.mustermann6@email.de  120000.0\n",
       "6       average7     joe.average7@email.com   70000.0\n",
       "7          Piet8     piet.yanneke8@email.nl  240000.0\n",
       "8    Mustermann9   max.mustermann9@email.de  180000.0\n",
       "9      average10    joe.average10@email.com  100000.0\n",
       "10        Piet11    piet.yanneke11@email.nl  330000.0\n",
       "11  Mustermann12  max.mustermann12@email.de  240000.0\n",
       "12     average13    joe.average13@email.com  130000.0\n",
       "13        Piet14    piet.yanneke14@email.nl  420000.0\n",
       "14  Mustermann15  max.mustermann15@email.de  300000.0\n",
       "15     average16    joe.average16@email.com  160000.0\n",
       "16        Piet17    piet.yanneke17@email.nl  510000.0\n",
       "17  Mustermann18  max.mustermann18@email.de  360000.0\n",
       "18     average19    joe.average19@email.com  190000.0\n",
       "19        Piet20    piet.yanneke20@email.nl  600000.0\n",
       "20  Mustermann21  max.mustermann21@email.de  420000.0\n",
       "21     average22    joe.average22@email.com  220000.0\n",
       "22        Piet23    piet.yanneke23@email.nl  690000.0\n",
       "23  Mustermann24  max.mustermann24@email.de  480000.0\n",
       "24     average25    joe.average25@email.com  250000.0\n",
       "25        Piet26    piet.yanneke26@email.nl  780000.0\n",
       "26  Mustermann27  max.mustermann27@email.de  540000.0\n",
       "27     average28    joe.average28@email.com  280000.0\n",
       "28        Piet29    piet.yanneke29@email.nl  870000.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## transfer data to pandas\n",
    "dfsqllitedata = pd.DataFrame(rows, columns=[x[0] for x in cursor.description])\n",
    "dfsqllitedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastname</th>\n",
       "      <th>email</th>\n",
       "      <th>networth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>average1</td>\n",
       "      <td>joe.average1@email.com</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Piet2</td>\n",
       "      <td>piet.yanneke2@email.nl</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mustermann3</td>\n",
       "      <td>max.mustermann3@email.de</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average4</td>\n",
       "      <td>joe.average4@email.com</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Piet5</td>\n",
       "      <td>piet.yanneke5@email.nl</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mustermann6</td>\n",
       "      <td>max.mustermann6@email.de</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>average7</td>\n",
       "      <td>joe.average7@email.com</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Piet8</td>\n",
       "      <td>piet.yanneke8@email.nl</td>\n",
       "      <td>240000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mustermann9</td>\n",
       "      <td>max.mustermann9@email.de</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>average10</td>\n",
       "      <td>joe.average10@email.com</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Piet11</td>\n",
       "      <td>piet.yanneke11@email.nl</td>\n",
       "      <td>330000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mustermann12</td>\n",
       "      <td>max.mustermann12@email.de</td>\n",
       "      <td>240000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>average13</td>\n",
       "      <td>joe.average13@email.com</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Piet14</td>\n",
       "      <td>piet.yanneke14@email.nl</td>\n",
       "      <td>420000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mustermann15</td>\n",
       "      <td>max.mustermann15@email.de</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>average16</td>\n",
       "      <td>joe.average16@email.com</td>\n",
       "      <td>160000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Piet17</td>\n",
       "      <td>piet.yanneke17@email.nl</td>\n",
       "      <td>510000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mustermann18</td>\n",
       "      <td>max.mustermann18@email.de</td>\n",
       "      <td>360000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>average19</td>\n",
       "      <td>joe.average19@email.com</td>\n",
       "      <td>190000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Piet20</td>\n",
       "      <td>piet.yanneke20@email.nl</td>\n",
       "      <td>600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mustermann21</td>\n",
       "      <td>max.mustermann21@email.de</td>\n",
       "      <td>420000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>average22</td>\n",
       "      <td>joe.average22@email.com</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Piet23</td>\n",
       "      <td>piet.yanneke23@email.nl</td>\n",
       "      <td>690000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mustermann24</td>\n",
       "      <td>max.mustermann24@email.de</td>\n",
       "      <td>480000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>average25</td>\n",
       "      <td>joe.average25@email.com</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Piet26</td>\n",
       "      <td>piet.yanneke26@email.nl</td>\n",
       "      <td>780000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mustermann27</td>\n",
       "      <td>max.mustermann27@email.de</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>average28</td>\n",
       "      <td>joe.average28@email.com</td>\n",
       "      <td>280000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Piet29</td>\n",
       "      <td>piet.yanneke29@email.nl</td>\n",
       "      <td>870000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lastname                      email  networth\n",
       "0       average1     joe.average1@email.com   10000.0\n",
       "1          Piet2     piet.yanneke2@email.nl   60000.0\n",
       "2    Mustermann3   max.mustermann3@email.de   60000.0\n",
       "3       average4     joe.average4@email.com   40000.0\n",
       "4          Piet5     piet.yanneke5@email.nl  150000.0\n",
       "5    Mustermann6   max.mustermann6@email.de  120000.0\n",
       "6       average7     joe.average7@email.com   70000.0\n",
       "7          Piet8     piet.yanneke8@email.nl  240000.0\n",
       "8    Mustermann9   max.mustermann9@email.de  180000.0\n",
       "9      average10    joe.average10@email.com  100000.0\n",
       "10        Piet11    piet.yanneke11@email.nl  330000.0\n",
       "11  Mustermann12  max.mustermann12@email.de  240000.0\n",
       "12     average13    joe.average13@email.com  130000.0\n",
       "13        Piet14    piet.yanneke14@email.nl  420000.0\n",
       "14  Mustermann15  max.mustermann15@email.de  300000.0\n",
       "15     average16    joe.average16@email.com  160000.0\n",
       "16        Piet17    piet.yanneke17@email.nl  510000.0\n",
       "17  Mustermann18  max.mustermann18@email.de  360000.0\n",
       "18     average19    joe.average19@email.com  190000.0\n",
       "19        Piet20    piet.yanneke20@email.nl  600000.0\n",
       "20  Mustermann21  max.mustermann21@email.de  420000.0\n",
       "21     average22    joe.average22@email.com  220000.0\n",
       "22        Piet23    piet.yanneke23@email.nl  690000.0\n",
       "23  Mustermann24  max.mustermann24@email.de  480000.0\n",
       "24     average25    joe.average25@email.com  250000.0\n",
       "25        Piet26    piet.yanneke26@email.nl  780000.0\n",
       "26  Mustermann27  max.mustermann27@email.de  540000.0\n",
       "27     average28    joe.average28@email.com  280000.0\n",
       "28        Piet29    piet.yanneke29@email.nl  870000.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TO DO transfer sqllite statement to pandas\n",
    "dfsqllitestatements = pd.DataFrame(rows, columns=[x[0] for x in cursor.description])\n",
    "dfsqllitestatements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO (loop)\n",
    "## sqlliteupdate1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO (loop)\n",
    "## sqllitedelete1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO (loop)\n",
    "## sqlliteselect1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Mongo DB\n",
    "\n",
    "https://www.w3schools.com/python/python_mongodb_getstarted.asp\n",
    "https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/#install-mongodb-community-edition\n",
    "\n",
    "See: https://docs.brew.sh/Homebrew-and-Python\n",
    "==> mongodb\n",
    "To have launchd start mongodb now and restart at login:\n",
    "  brew services start mongodb\n",
    "Or, if you don't want/need a background service you can just run:\n",
    "  mongod --config /usr/local/etc/mongod.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service `mongodb` already started, use `brew services restart mongodb` to restart.\r\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "!brew services start mongodb\n",
    "## !brew services stop mongodb\n",
    "## !brew services restart mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MongoDB waits until you have created a collection (table), \n",
    "## with at least one document (record) before it actually creates the database (and collection).\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "mydb = myclient[\"mydatabase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblist = myclient.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database exists.\n"
     ]
    }
   ],
   "source": [
    "if \"mydatabase\" in dblist:\n",
    "  print(\"The database exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'local', 'mydatabase']\n"
     ]
    }
   ],
   "source": [
    "print(myclient.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "mycol = mydb[\"Clients\"]\n",
    "mycol.drop()\n",
    "mycol = mydb[\"Clients\"]\n",
    "print(mydb.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = mydb.list_collection_names()\n",
    "if \"Clients\" in collist:\n",
    "  print(\"The collection exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mongo Inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'average1', 'emailid': 'joe.average1@email.com'},\n",
       " {'name': 'Piet2', 'emailid': 'piet.yanneke2@email.nl'},\n",
       " {'name': 'Mustermann3', 'emailid': 'max.mustermann3@email.de'},\n",
       " {'name': 'average4', 'emailid': 'joe.average4@email.com'},\n",
       " {'name': 'Piet5', 'emailid': 'piet.yanneke5@email.nl'},\n",
       " {'name': 'Mustermann6', 'emailid': 'max.mustermann6@email.de'},\n",
       " {'name': 'average7', 'emailid': 'joe.average7@email.com'},\n",
       " {'name': 'Piet8', 'emailid': 'piet.yanneke8@email.nl'},\n",
       " {'name': 'Mustermann9', 'emailid': 'max.mustermann9@email.de'},\n",
       " {'name': 'average10', 'emailid': 'joe.average10@email.com'},\n",
       " {'name': 'Piet11', 'emailid': 'piet.yanneke11@email.nl'},\n",
       " {'name': 'Mustermann12', 'emailid': 'max.mustermann12@email.de'},\n",
       " {'name': 'average13', 'emailid': 'joe.average13@email.com'},\n",
       " {'name': 'Piet14', 'emailid': 'piet.yanneke14@email.nl'},\n",
       " {'name': 'Mustermann15', 'emailid': 'max.mustermann15@email.de'},\n",
       " {'name': 'average16', 'emailid': 'joe.average16@email.com'},\n",
       " {'name': 'Piet17', 'emailid': 'piet.yanneke17@email.nl'},\n",
       " {'name': 'Mustermann18', 'emailid': 'max.mustermann18@email.de'},\n",
       " {'name': 'average19', 'emailid': 'joe.average19@email.com'},\n",
       " {'name': 'Piet20', 'emailid': 'piet.yanneke20@email.nl'},\n",
       " {'name': 'Mustermann21', 'emailid': 'max.mustermann21@email.de'},\n",
       " {'name': 'average22', 'emailid': 'joe.average22@email.com'},\n",
       " {'name': 'Piet23', 'emailid': 'piet.yanneke23@email.nl'},\n",
       " {'name': 'Mustermann24', 'emailid': 'max.mustermann24@email.de'},\n",
       " {'name': 'average25', 'emailid': 'joe.average25@email.com'},\n",
       " {'name': 'Piet26', 'emailid': 'piet.yanneke26@email.nl'},\n",
       " {'name': 'Mustermann27', 'emailid': 'max.mustermann27@email.de'},\n",
       " {'name': 'average28', 'emailid': 'joe.average28@email.com'},\n",
       " {'name': 'Piet29', 'emailid': 'piet.yanneke29@email.nl'}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data ={0 : ('Mustermann', 'max.mustermann@email.de', 20000),\n",
    "##        1 : ('average', 'joe.average@email.com', 10000),\n",
    "##        2 : ('Piet', 'piet.yanneke@email.nl', 30000)\n",
    "##        }\n",
    "\n",
    "## Collection Clients, with slightly different column names and one less\n",
    "mylist = [{ \"name\": \"Mustermann\", \"emailid\": \"max.mustermann@email.de\"}\n",
    "            ,{ \"name\": \"average\", \"emailid\": \"joe.average@email.com\"}\n",
    "            , {\"name\": \"Piet\", \"emailid\": \"piet.yanneke@email.nl\"}\n",
    "         ]\n",
    "\n",
    "## d = data['response']['globalstats']['heist_success']['history']\n",
    "## result_dict = dict((i[\"date\"],i[\"total\"]) for i in d)\n",
    "\n",
    "## mongoinsertlist ={}\n",
    "mongoinsertlist =[]\n",
    "i=1\n",
    "mongoinserttest = mylist[i%len(mylist)][\"name\"]\n",
    "mongoinserttest = []\n",
    "## mongoinsertlist = \"[\"\n",
    "while i < amountinserts:\n",
    "    mongoinsertnamekey = \"name\"\n",
    "    mongoinsertnamevalue =  mylist[i%len(mylist)][\"name\"] + str(i)  ## '\\\"'  \n",
    "    \n",
    "    mongoinsertemailidkey = \"emailid\"\n",
    "    mongoinsertemaildvalue =  mylist[i%len(mylist)][\"emailid\"] ## '\\\"'  ## insertChar(data[i%len(data)][1], data[i%len(data)][1].find('@'),str(i)) + \"\\',\" + str(i * data[i%len(data)][2]) + \")\"\n",
    "    mongoinsertemaildvalue = insertChar(mongoinsertemaildvalue, mongoinsertemaildvalue.find('@'),str(i))\n",
    "    \n",
    "    client = { mongoinsertnamekey : mongoinsertnamevalue , mongoinsertemailidkey : mongoinsertemaildvalue }\n",
    "    ##mycol.insert_one(mongoinsert)\n",
    "    mongoinsertlist.append(client)\n",
    "    i = i + 1\n",
    "    \n",
    "mongoinsertlist\n",
    "##mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insertChar??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mongoinsert1 = { \"name\": \"Mustermann\", \"emailid\": \"max.mustermann@email.de\"}\n",
    "## mongoinsert2 = { \"name\": \"average\", \"emailid\": \"joe.average@email.com\"}\n",
    "## mongoinsert3 = {\"name\": \"Piet\", \"emailid\": \"piet.yanneke@email.nl\"}\n",
    "\n",
    "## x1 = mycol.insert_one(mongoinsert1)\n",
    "## x2 = mycol.insert_one(mongoinsert2)\n",
    "## x3 = mycol.insert_one(mongoinsert3)\n",
    "\n",
    "## print(x1.inserted_id)\n",
    "## print(x2.inserted_id)\n",
    "## print(x3.inserted_id)\n",
    "\n",
    "mycol.drop()\n",
    "x = mycol.insert_many(mongoinsertlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'average1', 'emailid': 'joe.average1@email.com'}\n",
      "{'name': 'Piet2', 'emailid': 'piet.yanneke2@email.nl'}\n",
      "{'name': 'Mustermann3', 'emailid': 'max.mustermann3@email.de'}\n",
      "{'name': 'average4', 'emailid': 'joe.average4@email.com'}\n",
      "{'name': 'Piet5', 'emailid': 'piet.yanneke5@email.nl'}\n",
      "{'name': 'Mustermann6', 'emailid': 'max.mustermann6@email.de'}\n",
      "{'name': 'average7', 'emailid': 'joe.average7@email.com'}\n",
      "{'name': 'Piet8', 'emailid': 'piet.yanneke8@email.nl'}\n",
      "{'name': 'Mustermann9', 'emailid': 'max.mustermann9@email.de'}\n",
      "{'name': 'average10', 'emailid': 'joe.average10@email.com'}\n",
      "{'name': 'Piet11', 'emailid': 'piet.yanneke11@email.nl'}\n",
      "{'name': 'Mustermann12', 'emailid': 'max.mustermann12@email.de'}\n",
      "{'name': 'average13', 'emailid': 'joe.average13@email.com'}\n",
      "{'name': 'Piet14', 'emailid': 'piet.yanneke14@email.nl'}\n",
      "{'name': 'Mustermann15', 'emailid': 'max.mustermann15@email.de'}\n",
      "{'name': 'average16', 'emailid': 'joe.average16@email.com'}\n",
      "{'name': 'Piet17', 'emailid': 'piet.yanneke17@email.nl'}\n",
      "{'name': 'Mustermann18', 'emailid': 'max.mustermann18@email.de'}\n",
      "{'name': 'average19', 'emailid': 'joe.average19@email.com'}\n",
      "{'name': 'Piet20', 'emailid': 'piet.yanneke20@email.nl'}\n",
      "{'name': 'Mustermann21', 'emailid': 'max.mustermann21@email.de'}\n",
      "{'name': 'average22', 'emailid': 'joe.average22@email.com'}\n",
      "{'name': 'Piet23', 'emailid': 'piet.yanneke23@email.nl'}\n",
      "{'name': 'Mustermann24', 'emailid': 'max.mustermann24@email.de'}\n",
      "{'name': 'average25', 'emailid': 'joe.average25@email.com'}\n",
      "{'name': 'Piet26', 'emailid': 'piet.yanneke26@email.nl'}\n",
      "{'name': 'Mustermann27', 'emailid': 'max.mustermann27@email.de'}\n",
      "{'name': 'average28', 'emailid': 'joe.average28@email.com'}\n",
      "{'name': 'Piet29', 'emailid': 'piet.yanneke29@email.nl'}\n"
     ]
    }
   ],
   "source": [
    "## Get Data back\n",
    "## for x in mycol.find({},{ \"_id\": 0, \"name\": 1, \"emailid\": 1 }):\n",
    "##   print(x)\n",
    "\n",
    "## myquery = { \"name\": \"Mustermann\" }\n",
    "## mydoc = mycol.find(myquery)\n",
    "## for x in mydoc:\n",
    "##  print(x)\n",
    "\n",
    "##for x in mycol.find():\n",
    "##    print(x)\n",
    "rowsmongoiterator = mycol.find({},{ \"_id\": 0, \"name\": 1, \"emailid\": 1 })\n",
    "##rowsmongo\n",
    "for x in rowsmongoiterator:\n",
    "    ##rowsmongo = rowsmongo.add(x) ## append(x)\n",
    "    print(x)\n",
    "## rowsmongoiterator.explain   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO: doesnt work yet, but no problem. We want to zip the sql statements not the data\n",
    "## transfer data to pandas\n",
    "##dfmongodata = pd.DataFrame(rowsmongo)\n",
    "##dfmongodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mongo Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO (loop)\n",
    "## mongoupdate1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mongo Deletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO (loop)\n",
    "## mongodelete1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mongo Selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO (loop)\n",
    "## mongoselect1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building pairs of SQLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target format, same as for natural languages. Only the dot might not mark a sentence end, even though we could just add it.\n",
    "\n",
    "http://www.manythings.org/anki/\n",
    "\n",
    "    I'm ill.\tIk ben ziek.\n",
    "    I'm sad.\tIk ben bedroefd.\n",
    "    It's me!\tIk ben het.\n",
    "    It's me.\tIk ben het.\n",
    "    Join us.\tKom met ons mee.\n",
    "    Join us.\tDoe maar mee.\n",
    "    Join us.\tKom maar meedoen.\n",
    "    Join us.\tSluit je aan.\n",
    "    Join us.\tSluit je bij ons aan.\n",
    "    Keep it.\tHoud het.\n",
    "    See you!\tTot weerziens!\n",
    "    Shut up!\tZwijg!\n",
    "    Stop it.\tHou daar toch mee op.\n",
    "    \n",
    "Note, we need to make variable immutable, also we have a limited set of keywords (...)\n",
    "\n",
    "We do this with Panda .... we take the respective Insert, and Select statemeents from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqllite</th>\n",
       "      <th>mongo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average1','joe.a...</td>\n",
       "      <td>{'name': 'average1', 'emailid': 'joe.average1@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet2','piet.yan...</td>\n",
       "      <td>{'name': 'Piet2', 'emailid': 'piet.yanneke2@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann3','ma...</td>\n",
       "      <td>{'name': 'Mustermann3', 'emailid': 'max.muster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average4','joe.a...</td>\n",
       "      <td>{'name': 'average4', 'emailid': 'joe.average4@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet5','piet.yan...</td>\n",
       "      <td>{'name': 'Piet5', 'emailid': 'piet.yanneke5@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann6','ma...</td>\n",
       "      <td>{'name': 'Mustermann6', 'emailid': 'max.muster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average7','joe.a...</td>\n",
       "      <td>{'name': 'average7', 'emailid': 'joe.average7@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet8','piet.yan...</td>\n",
       "      <td>{'name': 'Piet8', 'emailid': 'piet.yanneke8@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann9','ma...</td>\n",
       "      <td>{'name': 'Mustermann9', 'emailid': 'max.muster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average10','joe....</td>\n",
       "      <td>{'name': 'average10', 'emailid': 'joe.average1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet11','piet.ya...</td>\n",
       "      <td>{'name': 'Piet11', 'emailid': 'piet.yanneke11@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann12','m...</td>\n",
       "      <td>{'name': 'Mustermann12', 'emailid': 'max.muste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average13','joe....</td>\n",
       "      <td>{'name': 'average13', 'emailid': 'joe.average1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet14','piet.ya...</td>\n",
       "      <td>{'name': 'Piet14', 'emailid': 'piet.yanneke14@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann15','m...</td>\n",
       "      <td>{'name': 'Mustermann15', 'emailid': 'max.muste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average16','joe....</td>\n",
       "      <td>{'name': 'average16', 'emailid': 'joe.average1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet17','piet.ya...</td>\n",
       "      <td>{'name': 'Piet17', 'emailid': 'piet.yanneke17@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann18','m...</td>\n",
       "      <td>{'name': 'Mustermann18', 'emailid': 'max.muste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average19','joe....</td>\n",
       "      <td>{'name': 'average19', 'emailid': 'joe.average1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet20','piet.ya...</td>\n",
       "      <td>{'name': 'Piet20', 'emailid': 'piet.yanneke20@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann21','m...</td>\n",
       "      <td>{'name': 'Mustermann21', 'emailid': 'max.muste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average22','joe....</td>\n",
       "      <td>{'name': 'average22', 'emailid': 'joe.average2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet23','piet.ya...</td>\n",
       "      <td>{'name': 'Piet23', 'emailid': 'piet.yanneke23@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann24','m...</td>\n",
       "      <td>{'name': 'Mustermann24', 'emailid': 'max.muste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average25','joe....</td>\n",
       "      <td>{'name': 'average25', 'emailid': 'joe.average2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet26','piet.ya...</td>\n",
       "      <td>{'name': 'Piet26', 'emailid': 'piet.yanneke26@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Mustermann27','m...</td>\n",
       "      <td>{'name': 'Mustermann27', 'emailid': 'max.muste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>INSERT INTO Customer VALUES ('average28','joe....</td>\n",
       "      <td>{'name': 'average28', 'emailid': 'joe.average2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>INSERT INTO Customer VALUES ('Piet29','piet.ya...</td>\n",
       "      <td>{'name': 'Piet29', 'emailid': 'piet.yanneke29@...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sqllite  \\\n",
       "0   INSERT INTO Customer VALUES ('average1','joe.a...   \n",
       "1   INSERT INTO Customer VALUES ('Piet2','piet.yan...   \n",
       "2   INSERT INTO Customer VALUES ('Mustermann3','ma...   \n",
       "3   INSERT INTO Customer VALUES ('average4','joe.a...   \n",
       "4   INSERT INTO Customer VALUES ('Piet5','piet.yan...   \n",
       "5   INSERT INTO Customer VALUES ('Mustermann6','ma...   \n",
       "6   INSERT INTO Customer VALUES ('average7','joe.a...   \n",
       "7   INSERT INTO Customer VALUES ('Piet8','piet.yan...   \n",
       "8   INSERT INTO Customer VALUES ('Mustermann9','ma...   \n",
       "9   INSERT INTO Customer VALUES ('average10','joe....   \n",
       "10  INSERT INTO Customer VALUES ('Piet11','piet.ya...   \n",
       "11  INSERT INTO Customer VALUES ('Mustermann12','m...   \n",
       "12  INSERT INTO Customer VALUES ('average13','joe....   \n",
       "13  INSERT INTO Customer VALUES ('Piet14','piet.ya...   \n",
       "14  INSERT INTO Customer VALUES ('Mustermann15','m...   \n",
       "15  INSERT INTO Customer VALUES ('average16','joe....   \n",
       "16  INSERT INTO Customer VALUES ('Piet17','piet.ya...   \n",
       "17  INSERT INTO Customer VALUES ('Mustermann18','m...   \n",
       "18  INSERT INTO Customer VALUES ('average19','joe....   \n",
       "19  INSERT INTO Customer VALUES ('Piet20','piet.ya...   \n",
       "20  INSERT INTO Customer VALUES ('Mustermann21','m...   \n",
       "21  INSERT INTO Customer VALUES ('average22','joe....   \n",
       "22  INSERT INTO Customer VALUES ('Piet23','piet.ya...   \n",
       "23  INSERT INTO Customer VALUES ('Mustermann24','m...   \n",
       "24  INSERT INTO Customer VALUES ('average25','joe....   \n",
       "25  INSERT INTO Customer VALUES ('Piet26','piet.ya...   \n",
       "26  INSERT INTO Customer VALUES ('Mustermann27','m...   \n",
       "27  INSERT INTO Customer VALUES ('average28','joe....   \n",
       "28  INSERT INTO Customer VALUES ('Piet29','piet.ya...   \n",
       "\n",
       "                                                mongo  \n",
       "0   {'name': 'average1', 'emailid': 'joe.average1@...  \n",
       "1   {'name': 'Piet2', 'emailid': 'piet.yanneke2@em...  \n",
       "2   {'name': 'Mustermann3', 'emailid': 'max.muster...  \n",
       "3   {'name': 'average4', 'emailid': 'joe.average4@...  \n",
       "4   {'name': 'Piet5', 'emailid': 'piet.yanneke5@em...  \n",
       "5   {'name': 'Mustermann6', 'emailid': 'max.muster...  \n",
       "6   {'name': 'average7', 'emailid': 'joe.average7@...  \n",
       "7   {'name': 'Piet8', 'emailid': 'piet.yanneke8@em...  \n",
       "8   {'name': 'Mustermann9', 'emailid': 'max.muster...  \n",
       "9   {'name': 'average10', 'emailid': 'joe.average1...  \n",
       "10  {'name': 'Piet11', 'emailid': 'piet.yanneke11@...  \n",
       "11  {'name': 'Mustermann12', 'emailid': 'max.muste...  \n",
       "12  {'name': 'average13', 'emailid': 'joe.average1...  \n",
       "13  {'name': 'Piet14', 'emailid': 'piet.yanneke14@...  \n",
       "14  {'name': 'Mustermann15', 'emailid': 'max.muste...  \n",
       "15  {'name': 'average16', 'emailid': 'joe.average1...  \n",
       "16  {'name': 'Piet17', 'emailid': 'piet.yanneke17@...  \n",
       "17  {'name': 'Mustermann18', 'emailid': 'max.muste...  \n",
       "18  {'name': 'average19', 'emailid': 'joe.average1...  \n",
       "19  {'name': 'Piet20', 'emailid': 'piet.yanneke20@...  \n",
       "20  {'name': 'Mustermann21', 'emailid': 'max.muste...  \n",
       "21  {'name': 'average22', 'emailid': 'joe.average2...  \n",
       "22  {'name': 'Piet23', 'emailid': 'piet.yanneke23@...  \n",
       "23  {'name': 'Mustermann24', 'emailid': 'max.muste...  \n",
       "24  {'name': 'average25', 'emailid': 'joe.average2...  \n",
       "25  {'name': 'Piet26', 'emailid': 'piet.yanneke26@...  \n",
       "26  {'name': 'Mustermann27', 'emailid': 'max.muste...  \n",
       "27  {'name': 'average28', 'emailid': 'joe.average2...  \n",
       "28  {'name': 'Piet29', 'emailid': 'piet.yanneke29@...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## zip a dataframe of \n",
    "\n",
    "\n",
    "##mongoinsertlist = [mongoinsert1, mongoinsert1, mongoinsert3]\n",
    "## sqlliteinsert1 mongoinsert1\n",
    "## sqlliteinsert2 mongoinsert2\n",
    "## sqlliteinsert3 mongoinsert3\n",
    "\n",
    "## sqlliteinsert1 : \"INSERT INTO Customer VALUES ('Mustermann', 'max.mustermann@email.de', 20000)\"\n",
    "## mongoinsert1 : {'name': 'Mustermann', 'emailid': 'max.mustermann@email.de', '_id': ObjectId('5bd5aad637b8896cc56ea929')}\n",
    "\n",
    "sql_tuples = list(zip(sqlliteinsertlist,mongoinsertlist ))\n",
    "pd.DataFrame(sql_tuples, columns=['sqllite','mongo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors - Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a list of words of the SQL dialect. Any other tokens are variables. Variables need to be immutable, that can be learnt by the model or we hardcode that. \n",
    "\n",
    "Can we run over docs or tickets of SQL to create word vectors?\n",
    "\n",
    "https://stackoverflow.com/search?q=postgres\n",
    "\n",
    "https://lxml.de/\n",
    "http://docs.python-requests.org/en/latest/\n",
    "\n",
    "http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/\n",
    "\n",
    "http://nlp.fast.ai/category/classification.html\n",
    "http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html\n",
    "\n",
    "https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb\n",
    "\n",
    "https://gist.github.com/mbednarski/da08eb297304f7a66a3840e857e060a0\n",
    "\n",
    "https://adoni.github.io/2017/11/08/word2vec-pytorch/\n",
    "\n",
    "\n",
    "https://gist.github.com/GavinXing/9954ea846072e115bb07d9758892382c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## following blog: https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb\n",
    "## this should get replaced by sql statements of both databases\n",
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital',\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is', 'a', 'king'],\n",
       " ['she', 'is', 'a', 'queen'],\n",
       " ['he', 'is', 'a', 'man'],\n",
       " ['she', 'is', 'a', 'woman'],\n",
       " ['warsaw', 'is', 'poland', 'capital'],\n",
       " ['berlin', 'is', 'germany', 'capital'],\n",
       " ['paris', 'is', 'france', 'capital']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## simplification, for \n",
    "def tokenize_corpus(corpus):\n",
    "    tokens = [x.split() for x in corpus]\n",
    "    return tokens\n",
    "\n",
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he': 0, 'is': 1, 'a': 2, 'king': 3, 'she': 4, 'queen': 5, 'man': 6, 'woman': 7, 'warsaw': 8, 'poland': 9, 'capital': 10, 'berlin': 11, 'germany': 12, 'paris': 13, 'france': 14}\n",
      "{0: 'he', 1: 'is', 2: 'a', 3: 'king', 4: 'she', 5: 'queen', 6: 'man', 7: 'woman', 8: 'warsaw', 9: 'poland', 10: 'capital', 11: 'berlin', 12: 'germany', 13: 'paris', 14: 'france'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for sentence in tokenized_corpus:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "print(word2idx)\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "print(idx2word)\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO: what is this?\n",
    "\n",
    "##We can now generate pairs center word, context word. \n",
    "##Lets assume context window to be symmetric and equal to 2.\n",
    "\n",
    "window_size = 2\n",
    "idx_pairs = []\n",
    "# for each sentence\n",
    "for sentence in tokenized_corpus:\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    # for each word, threated as center word\n",
    "    for center_word_pos in range(len(indices)):\n",
    "        # for each window position\n",
    "        for w in range(-window_size, window_size + 1):\n",
    "            context_word_pos = center_word_pos + w\n",
    "            # make soure not jump out sentence\n",
    "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
    "                continue\n",
    "            context_word_idx = indices[context_word_pos]\n",
    "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
    "\n",
    "idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives us list of pairs center, context indices, \n",
    "\n",
    "array([[ 0,  1],\n",
    "       [ 0,  2],\n",
    "       ...\n",
    "\n",
    "Which can be easily translated to words:\n",
    "\n",
    "he is\n",
    "he a\n",
    "is he\n",
    "is a\n",
    "is king\n",
    "a he\n",
    "a is\n",
    "a king"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input layer\n",
    "Input layer is just the center word encoded in one-hot manner. It dimensions are [1, vocabulary_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_layer(word_idx):\n",
    "    x = torch.zeros(vocabulary_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layer \n",
    "\n",
    "Hidden Layers makes our v vectors. Therefore it has to have embedding_dims neurons. To compute it value we have to define W1 weight matrix. Of course its has to be [embedding_dims, vocabulary_size]. There is no activation functionjust plain matrix multiplication.\n",
    "\n",
    "x is one-hot and if you multiply one-hot vector by matrix, the result is same as selecting select single column from it. Therefore, each column of W1 stores v vector for single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bherudek/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epo 0: 4.759732723236084\n",
      "Loss at epo 10: 4.197955131530762\n",
      "Loss at epo 20: 3.7988269329071045\n",
      "Loss at epo 30: 3.516937732696533\n",
      "Loss at epo 40: 3.3159615993499756\n",
      "Loss at epo 50: 3.1684799194335938\n",
      "Loss at epo 60: 3.0558013916015625\n",
      "Loss at epo 70: 2.9662201404571533\n",
      "Loss at epo 80: 2.8926713466644287\n",
      "Loss at epo 90: 2.830836534500122\n",
      "Loss at epo 100: 2.7779338359832764\n"
     ]
    }
   ],
   "source": [
    "embedding_dims = 5\n",
    "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
    "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
    "num_epochs = 101\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epo in range(num_epochs):\n",
    "    loss_val = 0\n",
    "    for data, target in idx_pairs:\n",
    "        x = Variable(get_input_layer(data)).float()\n",
    "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
    "\n",
    "        z1 = torch.matmul(W1, x)\n",
    "        z2 = torch.matmul(W2, z1)\n",
    "    \n",
    "        log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "        loss_val += loss.data[0]\n",
    "        loss.backward()\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "    if epo % 10 == 0:    \n",
    "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output layer\n",
    "\n",
    "Last layer must have vocabulary_size neuronsbecause it generates probabilities for each word. Therefore, W2 is [vocabulary_size, embedding_dims] in terms of shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4f1fa0a9ddeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Variable' is not defined"
     ]
    }
   ],
   "source": [
    "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
    "z2 = torch.matmul(W2, z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top on that we have to use softmax layer. PyTorch provides optimized version of this, combined with logbecause regular softmax is not really numerically stable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f013d2b0c12d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "log_softmax = F.log_softmax(a2, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to compute softmax and after that applying log.Now we can compute the loss. As usual PyTorch provides everything we need.\n",
    "\n",
    "The nll_loss computes negative-log-likelihood on logsoftmax. y_true is context wordwe want to make this as high as possiblebecause pair x, y_true is from training dataso the are indeed center, context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f333a5792059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "loss = F.nll_loss(log_softmax.view(1,-1), y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optimization SDG is used. It is so simple, that it was faster to write it by hand instead of creating optimizer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1.data -= 0.01 * W1.grad.data\n",
    "W2.data -= 0.01 * W2.grad.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to zero gradients to make next pass clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-15f450a05668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W1' is not defined"
     ]
    }
   ],
   "source": [
    "W1.grad.data.zero_()\n",
    "W2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One potentially tricky thing is y_true definition. We do not create one-hot explicitlynll_loss does it by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-65b35229e01a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Variable' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_dims = 5\n",
    "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
    "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epo in range(num_epochs):\n",
    "    loss_val = 0\n",
    "    for data, target in idx_pairs:\n",
    "        x = Variable(get_input_layer(data)).float()\n",
    "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
    "\n",
    "        z1 = torch.matmul(W1, x)\n",
    "        z2 = torch.matmul(W2, z1)\n",
    "    \n",
    "        log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "        loss_val += loss.data[0]\n",
    "        loss.backward()\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "    if epo % 10 == 0:    \n",
    "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have trained the network. One, last thing is to extract vectors for words. It is possible in three ways:\n",
    "\n",
    "- Use vector v from W1\n",
    "- Use vector u from W2\n",
    "- Use average v and u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Language Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a word vector manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial SQL languages are less complex, building a word vector and a language model is easy (). \n",
    "\n",
    "One consider building a word vector from a documentation (?) or log file (?). The issue is, we only want SQL not the log constructus or natural language around it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors fas.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fastai/word-embeddings-workshop\n",
    "\n",
    "https://www.youtube.com/watch?v=25nC0n9ERq4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available at http://files.fast.ai/models/glove/6B.100d.tgz To download and unzip the files from the command line, you can run:\n",
    "\n",
    "- wget http://files.fast.ai/models/glove_50_glove_100.tgz \n",
    "- Mac: curl -O http://files.fast.ai/models/glove_50_glove_100.tgz    \n",
    "- tar xvzf glove_50_glove_100.tgz\n",
    "\n",
    "You will need to update the path below to be accurate for where you are storing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pwd\n",
    "##!curl -O http://files.fast.ai/models/glove_50_glove_100.tgz    \n",
    "##!tar xvzf glove_50_glove_100.tgz\n",
    "##!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.load(\"glove_vectors_100d.npy\")\n",
    "vecs50 = np.load(\"glove_vectors_50d.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words.txt') as f:\n",
    "    content = f.readlines()\n",
    "words = [x.strip() for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordidx = json.load(open('wordsidx.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['together',\n",
       " 'congress',\n",
       " 'index',\n",
       " 'australia',\n",
       " 'results',\n",
       " 'hard',\n",
       " 'hours',\n",
       " 'land',\n",
       " 'action',\n",
       " 'higher']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[600:610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wordidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11853"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordidx['feminist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feminist'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[11853]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word as Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"intelligence\" is represented by the 100 dimensional vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.296 ,  0.7626, -0.9866,  0.3776,  0.3194,  0.8286, -0.1686,\n",
       "       -1.4558,  0.1965,  0.3854, -0.3348, -0.6503, -0.2528, -0.11  ,\n",
       "       -0.1545,  0.5354, -0.4527, -0.0516,  0.1312,  0.0744,  0.5001,\n",
       "        0.2151,  0.0688,  0.4347,  0.261 , -0.0371,  0.1385, -1.518 ,\n",
       "        0.0641,  0.149 , -0.0314,  0.5038,  0.2839,  0.3457, -0.4411,\n",
       "       -0.3459, -0.2118,  0.5651, -0.088 , -0.0438, -1.2228,  0.6039,\n",
       "       -0.23  ,  0.2287, -0.2695, -0.9398,  0.2376,  0.3302, -0.2422,\n",
       "        0.6359,  0.1347,  0.5542,  0.1432,  0.2861,  0.0216, -0.7437,\n",
       "        0.3508,  0.362 ,  0.5566,  0.3403,  0.3613,  0.5185, -0.5437,\n",
       "       -0.285 ,  1.1831, -0.1192,  0.2473,  0.0614,  0.4436, -0.244 ,\n",
       "        0.2016,  0.5143, -0.4695, -0.0974, -0.9836, -0.3594,  0.3903,\n",
       "       -0.517 , -0.1659, -1.2132, -1.3228,  0.0578,  0.7022,  0.3492,\n",
       "       -0.9103, -0.381 , -0.1545,  0.4467, -0.009 , -0.9838,  1.0114,\n",
       "       -0.227 ,  0.2697,  0.1566,  0.5613,  0.1175, -0.5755, -0.6324,\n",
       "        0.1052,  1.2465], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[11853]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets us do some useful calculations. For instance, we can see how far apart two words are using a distance metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller numbers mean two words are closer together, larger numbers mean they are further apart.\n",
    "\n",
    "The distance between similar words is low:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27636247873306274"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"puppy\"]], vecs[wordidx[\"dog\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20527541637420654"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"queen\"]], vecs[wordidx[\"princess\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the distance between unrelated words is high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883578838780522"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"celebrity\"]], vecs[wordidx[\"dusty\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8729851841926575"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"kitten\"]], vecs[wordidx[\"airplane\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9621107056736946"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"avalanche\"]], vecs[wordidx[\"antique\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Continue at Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSql\n",
    "\n",
    "https://www.w3schools.com/python/python_mysql_getstarted.asp\n",
    "\n",
    "To have launchd start mysql now and restart at login:\n",
    "  brew services start mysql\n",
    "Or, if you don't want/need a background service you can just run:\n",
    "  mysql.server start\n",
    "  \n",
    "  cnx = mysql.connector.connect(user='lcherukuri', password='password',\n",
    "                              host='127.0.0.1', database='test',\n",
    "                              auth_plugin='mysql_native_password')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"yourusername\",\n",
    "  passwd=\"yourpassword\",\n",
    "  auth_plugin=\"mysql_native_password\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "mycursor.execute(\"CREATE DATABASE mydatabase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sqllite does the same thing: hardcoded while we want to train a model\n",
    "## https://www.sqlalchemy.org/\n",
    "\n",
    "import sqlalchemy as sqla\n",
    "\n",
    "db = sqla.create_engine('sqlite:///mydata.sqlite')\n",
    "\n",
    "pd.read_sql('select lastname, email, networth from Customer', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other python drivers\n",
    "\n",
    "- PYODBC: https://pypi.org/project/pyodbc/\n",
    "- psycopg2: http://initd.org/psycopg/\n",
    "- MySQLdb:\n",
    "    https://dev.mysql.com/downloads/connector/python/\n",
    "    https://www.w3schools.com/python/python_mysql_create_db.asp\n",
    "- pymssql: http://www.pymssql.org/en/stable/\n",
    "- https://www.w3schools.com/python/python_mongodb_getstarted.asp \n",
    "--> next step could be translating to such a document based DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postgrese\n",
    "# https://www.postgresql.org/docs/9.4/static/sql.html\n",
    "# http://initd.org/psycopg/\n",
    "\n",
    "# import psycopg2\n",
    "\n",
    "# Connect to an existing database\n",
    "# conn = psycopg2.connect(\"dbname=test user=postgres\")\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# Execute a command: this creates a new table\n",
    "# cur.execute(\"CREATE TABLE test (id serial PRIMARY KEY, num integer, data varchar);\")\n",
    "\n",
    "# Pass data to fill a query placeholders and let Psycopg perform\n",
    "# the correct conversion (no more SQL injections!)\n",
    "# cur.execute(\"INSERT INTO test (num, data) VALUES (%s, %s)\",    (100, \"abc'def\"))\n",
    "\n",
    "# Query the database and obtain data as Python objects\n",
    "# cur.execute(\"SELECT * FROM test;\")\n",
    "# cur.fetchone()\n",
    "# (1, 100, \"abc'def\")\n",
    "\n",
    "# Make the changes to the database persistent\n",
    "# conn.commit()\n",
    "\n",
    "# Close communication with the database\n",
    "# cur.close()\n",
    "# conn.close()"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "ALP/PairedSQLDataset/PairedSQLDatasetTODO.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
